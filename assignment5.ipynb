{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74634566",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Reddit Dataset\n",
    "\n",
    "This notebook demonstrates data preprocessing steps including handling missing values, data transformation, normalization, encoding, and feature engineering for predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ee3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'path_to_your_file/Reddit.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data.info(), data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d94b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "data['title'].fillna('No Title', inplace=True)\n",
    "data['content'].fillna('No Content', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd02e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation: converting 'creation time' to datetime\n",
    "data['creation time'] = pd.to_datetime(data['creation time'], format='%Y%m%d %H%M%S')\n",
    "\n",
    "# Extracting additional features from 'creation time'\n",
    "data['year'] = data['creation time'].dt.year\n",
    "data['month'] = data['creation time'].dt.month\n",
    "data['day'] = data['creation time'].dt.day\n",
    "data['hour'] = data['creation time'].dt.hour\n",
    "data['minute'] = data['creation time'].dt.minute\n",
    "data['second'] = data['creation time'].dt.second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ecc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of numerical columns\n",
    "scaler = StandardScaler()\n",
    "data[['score', 'comments']] = scaler.fit_transform(data[['score', 'comments']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "encoder = LabelEncoder()\n",
    "data['subreddit'] = encoder.fit_transform(data['subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that may not be necessary for predictive modeling\n",
    "data.drop(columns=['id', 'url', 'creation time'], inplace=True)\n",
    "\n",
    "# Display the preprocessed data\n",
    "data.info(), data.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
